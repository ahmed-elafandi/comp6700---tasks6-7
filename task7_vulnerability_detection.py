import pandas as pd
import subprocess
import tempfile
import os
import requests
from pathlib import Path
import json
import sys
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
import time

# Create session with retry strategy
def create_session():
    session = requests.Session()
    retry = Retry(connect=3, backoff_factor=0.5, status_forcelist=(500, 502, 503, 504))
    adapter = HTTPAdapter(max_retries=retry)
    session.mount('http://', adapter)
    session.mount('https://', adapter)
    return session

SESSION = create_session()

def is_python_file(filename):
    """Check if file is a Python file"""
    if not filename or pd.isna(filename):
        return False
    return str(filename).endswith('.py')

def get_file_from_github(repo_url, commit_sha, filename, timeout=10):
    """
    Download a file from GitHub at a specific commit.
    """
    if not repo_url or not commit_sha or not filename:
        return None, False

    if pd.isna(repo_url) or pd.isna(commit_sha) or pd.isna(filename):
        return None, False

    try:
        # Convert git URLs to https if needed
        if repo_url.endswith('.git'):
            repo_url = repo_url[:-4]
        if repo_url.startswith('git@github.com:'):
            repo_url = repo_url.replace('git@github.com:', 'https://github.com/')

        # Extract owner/repo
        parts = repo_url.rstrip('/').split('/')
        if len(parts) >= 2:
            owner = parts[-2]
            repo = parts[-1]
        else:
            return None, False

        # Build raw GitHub URL
        raw_url = f"https://raw.githubusercontent.com/{owner}/{repo}/{commit_sha}/{filename}"

        response = SESSION.get(raw_url, timeout=timeout)
        if response.status_code == 200:
            return response.text, True
        else:
            return None, False
    except Exception:
        return None, False

def run_bandit_on_file(file_content, filename):
    """
    Run Bandit on file content and check for vulnerabilities.
    """
    if not file_content or not is_python_file(filename):
        return False, "Not a Python file or no content"

    try:
        # Create temporary file
        with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False, encoding='utf-8', errors='ignore') as f:
            temp_file = f.name
            f.write(file_content)

        try:
            # Run Bandit with timeout
            result = subprocess.run(
                ['bandit', temp_file, '-f', 'json', '-ll'],
                capture_output=True,
                text=True,
                timeout=30
            )

            # Parse JSON output
            try:
                output = json.loads(result.stdout)
                has_vulns = len(output.get('results', [])) > 0
                return has_vulns, None
            except Exception:
                return False, "Could not parse Bandit output"

        finally:
            # Clean up temp file
            if os.path.exists(temp_file):
                try:
                    os.unlink(temp_file)
                except Exception:
                    pass

    except subprocess.TimeoutExpired:
        return False, "Bandit timeout"
    except FileNotFoundError:
        return False, "Bandit not installed"
    except Exception as e:
        return False, str(e)

def process_task7():
    """Process Task-7: Add VULNERABLEFILE column to Task-4 CSV"""

    print("=" * 70)
    print("Task-7: Vulnerability Detection with Bandit")
    print("=" * 70)
    print()

    # Check if Bandit is installed
    try:
        subprocess.run(['bandit', '--version'], capture_output=True, check=True, timeout=5)
        print("[OK] Bandit is installed")
    except Exception:
        print("[ERROR] Bandit not installed. Installing...")
        subprocess.run([sys.executable, '-m', 'pip', 'install', 'bandit'], check=True, timeout=120)
        print("[OK] Bandit installed")

    print()

    # Load Task-4 CSV and Task-1 CSV to get repo URLs
    print("Loading Task-4 commit details...")
    task4_df = pd.read_csv('task4_commit_details.csv')
    print(f"[OK] Loaded {len(task4_df)} commit records")

    print("Loading Task-1 pull requests for repo URLs...")
    task1_df = pd.read_csv('task1_pull_requests.csv')
    print(f"[OK] Loaded {len(task1_df)} pull requests")


    # Prepare data - merge to get repo URLs
    print("Merging data to get repository URLs...")
    merged = task4_df.merge(
        task1_df[['ID', 'REPOURL']],
        left_on='PRID',
        right_on='ID',
        how='left'
    )
    print(f"[OK] Merged successfully")
    print()

    # Initialize vulnerability column
    vulnerabilities = []
    total_files = len(merged)
    processed = 0
    python_files = 0
    vulnerable_files = 0
    skipped_files = 0

    print(f"Processing {total_files} files for vulnerabilities...")
    print("(This may take a while due to GitHub requests)")
    print()

    start_time = time.time()

    # ***** LIMIT FOR ASSIGNMENT SUBMISSION *****
    # Only scan the first N records so the script finishes in reasonable time.
    MAX_FILES = 300 
    # *******************************************

    for idx, row in merged.iterrows():
        if processed >= MAX_FILES:
            print(f"[INFO] Reached MAX_FILES={MAX_FILES}. Stopping early.")
            break

        processed += 1

        # Show progress every 100 records
        if processed % 100 == 0 or processed == MAX_FILES:
            elapsed = time.time() - start_time
            rate = processed / elapsed if elapsed > 0 else 0
            eta = (MAX_FILES - processed) / rate if rate > 0 else 0
            print(f"[Progress] {processed}/{MAX_FILES} files ({int(rate)}/sec, ETA: {int(eta)}s) "
                  f"| Python: {python_files} | Vulnerable: {vulnerable_files} | Skipped: {skipped_files}")

        filename = row['PRFILE']
        repo_url = row['REPOURL']
        commit_sha = row['PRSHA']

        # Check if Python file
        if not is_python_file(filename):
            vulnerabilities.append(0)
            continue

        python_files += 1

        # Try to get file from GitHub with timeout
        file_content, success = get_file_from_github(repo_url, commit_sha, filename, timeout=5)

        if not success or not file_content:
            vulnerabilities.append(0)
            skipped_files += 1
            continue

        # Run Bandit
        has_vulns, error = run_bandit_on_file(file_content, filename)

        if has_vulns:
            vulnerable_files += 1
            vulnerabilities.append(1)
        else:
            vulnerabilities.append(0)

    # Pad the rest of the rows (that we didn't process) with 0
    if len(vulnerabilities) < total_files:
        remaining = total_files - len(vulnerabilities)
        vulnerabilities.extend([0] * remaining)

    print()
    print("[OK] Vulnerability detection complete (limited run)")
    print()

    # Add VULNERABLEFILE column
    task4_df['VULNERABLEFILE'] = vulnerabilities

    # Save to CSV
    output_file = 'task7_commit_details_vulnerable.csv'
    task4_df.to_csv(output_file, index=False)
    print(f"[OK] Saved to {output_file}")
    print()
    print("=" * 70)
    print("Task-7 Summary:")
    print(f"  Total rows in Task-4:       {total_files}")
    print(f"  Files actually processed:   {processed}")
    print(f"  Python files among those:   {python_files}")
    print(f"  Files with vulnerabilities: {vulnerable_files}")
    print(f"  Files skipped (unavailable):{skipped_files}")
    print(f"  Output file: {output_file}")
    elapsed = time.time() - start_time
    print(f"  Total time: {elapsed:.1f}s")
    print("  Note: Rows beyond MAX_FILES are marked VULNERABLEFILE = 0 by default.")
    print("=" * 70)

if __name__ == "__main__":
    try:
        process_task7()
    except KeyboardInterrupt:
        print("\n\n[CANCELLED] Task-7 interrupted by user")
        sys.exit(1)
    except Exception as e:
        print(f"[ERROR] {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
